<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Zhutian Yang - Site</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Zhutian Yang is a PhD student at MIT">
    <link rel="stylesheet" href="css/main.css">
  </head>
  <body>
    <table>
      <tbody>
        <tr>
          <td class="bio">
            <h1 class="name center">Zhutian Yang</h1>
            <div class="email center">ztyang {at} mit {dot} edu</div>
            <p>Hello! My name is Zhutian and I'm a second-year PhD student at MIT
                working on machine learning for speed up task and motion planning so that we can have mobile robots helping with household chores. I'm co-advised by Leslie Pack Kaelbling and Tomás Lozano-Pérez. </p>
          </td>
          <td class="photo">
            <img src="https://raw.githubusercontent.com/zt-yang/zhutian-yang-website/main/img/zhutianyang.jpg?token=GHSAT0AAAAAABZLZPSEQFWPM4YB67NHZED4Y3CZFKQ" width="100%">
          </td>
        </tr>
      </tbody>
    </table>


    <h2>Research</h2>
    Household robots planning long-horizon behavior, such as heating up takeouts and cleaning the kitchen counter, must be able to plan quickly and execute robustly. I'm working on the following problems in the field of robotic Task and Motion Planning (TAMP):
    <ul>
      <li> Hierarchical planning and replanning </li>
      <li> Learn to predict plan feasibility from images </li>
      <li> Learn to solve constraint satisfaction problems (e.g. bin packing problem) </li>
    </ul>

    <img class="figure" src="https://github.com/zt-yang/zhutian-yang-website/blob/main/img/piginet_tasks.gif?raw=true">
    <p class="caption"> Figure: Robots learning to plan motion faster for rearrangement tasks </p>

    <h2>Publications</h2>
    <ul class="publications">
      
        <li class="pub">
          <p>
            <span class="pub-title">Sequence-Based Plan Feasibility Prediction for Efficient Task and Motion Planning</span></p>
          <p><span class="self-author">Zhutian Yang</span>, Caelan Reed Garrett, and Dieter Fox</p>
          <p>CoRL 2022, Workshop on Learning, Perception, and Abstraction for Long-Horizon Planning</p>
          <p><p style="color: grey"><i>&#128293; We won Best Paper Runner-Up!</i></p><a href="http://arxiv.org/abs/2211.01576">[Paper]</a></p>
        </li>
      
        <li class="pub">
          <p>
            <span class="pub-title">Let’s Handle It: Generalizable Manipulation of Articulated Objects</span></p>
          <p><span class="self-author">Zhutian Yang</span>, and Aidan Curtis</p>
          <p>ICRL 2022, Generalizable Policy Learning in the Physical World</p>
          <p><p style="color: grey"><i>&#128293; We won 2nd place in the ManiSkill Challenge 2022 Robotics Track</i></p><a href="https://openreview.net/pdf?id=SObVnEp4yb9">[Paper]</a></p>
        </li>
      
    </ul>
  </body>
</html>
